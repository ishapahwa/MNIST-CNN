{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import skimage.transform\n",
    "import skimage.util\n",
    "from skimage.io import imread\n",
    "\n",
    "#from preprocessing import preprocess_image\n",
    "\n",
    "# machine learning packages\n",
    "import tensorflow as tf\n",
    "\n",
    "########\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Dropout , Lambda, Flatten\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras import  backend as K\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "##########\n",
    "\n",
    "#from keras.layers.core import  Lambda , Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau \n",
    "from tensorflow.keras.layers import BatchNormalization, Convolution2D\n",
    "#from keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "#from keras.preprocessing import image\n",
    "#from keras.utils import layer_utils\n",
    "#from keras.utils.data_utils import get_file\n",
    "#from keras.applications.imagenet_utils import preprocess_input\n",
    "#import pydot\n",
    "#from IPython.display import SVG\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "#from keras.utils import plot_model\n",
    "#from kt_utils import *\n",
    "from tensorflow.keras import optimizers\n",
    "import preprocessing\n",
    "\n",
    "### Changed to Keras.something to tensorflow.keras.something to avoid the error the backend issues.\n",
    "### There were conflicting issues with Tensorflow 2.0 and keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading training data\n",
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is a 784 pixels, can be written into 28$\\times$28 matrix which represents a digit. Let's drop the first column in order to read rows for digits.\n",
    "\n",
    "Labels varies from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig = (train.iloc[:,1:].values).astype('float32') # all rows\n",
    "Y_train_orig = train.iloc[:,0].values.astype('int32') # all labels\n",
    "X_test_orig = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_orig, Y_train_orig, test_size=0.10, random_state=56)\n",
    "Y_train=Y_train.astype('int32')\n",
    "Y_val=Y_val.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[0:3000]\n",
    "Y_train = Y_train[0:3000]\n",
    "X_val = X_val[0:300]\n",
    "Y_val = Y_val[0:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert train dataset to (num_images, img_rows, img_cols) format \n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test_orig.reshape(X_test_orig.shape[0], 28, 28, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28,1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## printing random hand-written digits\n",
    "indx = np.random.randint(0,len(X_train)-1,size=10)\n",
    "fig = plt.figure()\n",
    "for ix in range(10):\n",
    "    ax = fig.add_subplot(5, 5, 1 + ix)\n",
    "    ax.imshow(X_train[indx[ix],:,:,0])\n",
    "    ax.set_title('y='+str(Y_train[indx[ix]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reducing the pixels values between 0 and 1\n",
    "Xn_train = X_train/255.\n",
    "Xn_test = X_test/255.\n",
    "Xn_val = X_val/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def convert_to_one_hot(Y, C):\n",
    "#    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "#    return Y\n",
    "#Y_train = convert_to_one_hot(Y_train, 10).T\n",
    "#Y_val = convert_to_one_hot(Y_val, 10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of different labels 10\n"
     ]
    }
   ],
   "source": [
    "Ye_train= to_categorical(Y_train)\n",
    "Ye_val= to_categorical(Y_val)\n",
    "nlabels = Ye_train.shape[1]\n",
    "print('Total number of different labels',nlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the LinearModel.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    # Define the input placeholder as a tensor with shape input_shape. \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X_input)\n",
    "    X = Dense(10, activation='softmax', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='LinearModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_run(Model,xdata,ydata,xval,yval,bs):\n",
    "    model = Model(Xn_train[-1].shape)\n",
    "    model.compile(optimizers.Adam(lr=0.01), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    history = model.fit(x = Xn_train, y = Ye_train, epochs = 40, batch_size = 64)\n",
    "    mval =  model.evaluate(x = xval, y = yval)\n",
    "    return mval,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val,his=lm_run(LinearModel,Xn_train,Ye_train, Xn_val, Ye_val,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(his.history['accuracy'])\n",
    "plt.scatter(40,val[1])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(his.history['loss'])\n",
    "plt.scatter(40,val[0])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convulational Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the ConvModel.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    # Define the input placeholder as a tensor with shape input_shape. \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(10, activation='softmax', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='ConvModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val,his=lm_run(ConvModel,Xn_train,Ye_train, Xn_val, Ye_val,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(his.history['accuracy'])\n",
    "plt.scatter(40,val[1])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(his.history['loss'])\n",
    "plt.scatter(40,val[0])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurapan CNN_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestConvModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the ConvModel.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    # Define the input placeholder as a tensor with shape input_shape. \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # \n",
    "    X = ZeroPadding2D((2, 2))(X_input)\n",
    "    X = Conv2D(64,5,5,kernel_initializer='he_normal',padding='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = ZeroPadding2D((2, 2))(X)\n",
    "    X = Conv2D(128,5,5,kernel_initializer='he_normal',padding='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(strides=(2, 2),padding='same')(X)\n",
    "   \n",
    "    #\n",
    "    X = ZeroPadding2D((2, 2))(X)\n",
    "    X = Conv2D(256,5,5,kernel_initializer='he_normal',padding='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = ZeroPadding2D((1, 1))(X)\n",
    "    X = Conv2D(256,3,3,kernel_initializer='he_normal',padding='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(strides=(2, 2),padding='same')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    #\n",
    "    X = ZeroPadding2D((1, 1))(X)\n",
    "    X = Conv2D(512,2,3,kernel_initializer='he_normal',padding='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = ZeroPadding2D((1, 1))(X)\n",
    "    X = Conv2D(512,3,3,kernel_initializer='he_normal',padding='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(strides=(2, 2),padding='same')(X)\n",
    "    \n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(2048, activation='relu', kernel_initializer='he_normal')(X)\n",
    "\n",
    "    predictions = Dense(10, activation=\"softmax\")(X)\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = predictions, name='ConvModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_and_shear(img, rotation_angle=15, shear_angle=30):\n",
    "    img = skimage.transform.rotate(img, np.random.randint(-rotation_angle, rotation_angle))\n",
    "    tf_shift = skimage.transform.SimilarityTransform(translation=(-14, -14))\n",
    "    tf_inv_shift = skimage.transform.SimilarityTransform(translation=(14, 14))\n",
    "    tf_shear = skimage.transform.AffineTransform(shear=np.deg2rad(np.random.randint(-shear_angle, shear_angle)))\n",
    "    img = skimage.transform.warp(img, (tf_shift + (tf_shear + tf_inv_shift)).inverse)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_pixels(img, shift_range=1):\n",
    "    tf_shift = skimage.transform.SimilarityTransform(translation=(np.random.randint(-shift_range, shift_range), np.random.randint(-shift_range, shift_range)))\n",
    "    img = skimage.transform.warp(img, tf_shift)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img, gauss_var=0.02):\n",
    "    #img = skimage.util.random_noise(img, mode='pepper', amount=0.1)\n",
    "    img = skimage.util.random_noise(img, mode='gaussian', var=gauss_var)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(trainX, trainY, batch_size):\n",
    "    trainX = trainX.reshape(trainX.shape[0],1,trainX.shape[1],trainX.shape[2])\n",
    "    while True:\n",
    "        idxs = np.arange(0, trainY.shape[0])\n",
    "        np.random.shuffle(idxs)\n",
    "        for i in range(trainY.shape[0] // batch_size):\n",
    "            batchX = [trainX[idx] for idx in idxs[i * batch_size : (i+1) * batch_size]]\n",
    "            batchY = [trainY[idx] for idx in idxs[i * batch_size : (i+1) * batch_size]]\n",
    "            batchX = [add_noise(rotation_and_shear(img[0])) for img in batchX]\n",
    "            batchX = np.array(batchX)\n",
    "            batchX = batchX.reshape(batchX.shape[0], batchX.shape[1], batchX.shape[2], 1)\n",
    "            #return batchX, batchY\n",
    "            yield batchX, np.array(batchY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(Model,xdata,ydata,xval,yval,xtest,bs,nb):\n",
    "    #xdata = xdata.reshape(xdata.shape[0],1,xdata.shape[1],xdata.shape[2])\n",
    "    model = Model(xdata[-1].shape)\n",
    "    model.compile(optimizers.Adam(lr=0.001,beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    # reduce the learning rate by factor of 0.5 if the validation loss does not get lower in 7 epochs\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=0.0000001, verbose=1)\n",
    "    history = model.fit_generator(batch_generator(xdata, ydata, batch_size=bs),steps_per_epoch=np.ceil(ydata.shape[0] / bs),validation_data=(xval, yval),epochs=nb, verbose=1, callbacks=[reduce_lr])\n",
    "    ##history = model.fit(x = xdata, y = ydata, epochs = 40, batch_size = bs,validation_data= (xval,yval),callbacks=[es])\n",
    "    mval =  model.evaluate(x = xval, y = yval)\n",
    "    ytest=model.predict(xtest)\n",
    "    return mval,history,ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx,testy=batch_generator(Xn_train, Ye_train, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "591/591 [==============================] - 256s 434ms/step - loss: 0.6310 - accuracy: 0.7989 - val_loss: 0.1846 - val_accuracy: 0.9495\n",
      "Epoch 2/70\n",
      "591/591 [==============================] - 254s 430ms/step - loss: 0.2674 - accuracy: 0.9244 - val_loss: 0.1274 - val_accuracy: 0.9621\n",
      "Epoch 3/70\n",
      "591/591 [==============================] - 239s 405ms/step - loss: 0.2104 - accuracy: 0.9433 - val_loss: 0.1041 - val_accuracy: 0.9679\n",
      "Epoch 4/70\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.1824 - accuracy: 0.9501 - val_loss: 0.1253 - val_accuracy: 0.9705\n",
      "Epoch 5/70\n",
      "591/591 [==============================] - 239s 404ms/step - loss: 0.1640 - accuracy: 0.9557 - val_loss: 0.1010 - val_accuracy: 0.9712\n",
      "Epoch 6/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.1450 - accuracy: 0.9599 - val_loss: 0.0908 - val_accuracy: 0.9771\n",
      "Epoch 7/70\n",
      "591/591 [==============================] - 238s 402ms/step - loss: 0.1393 - accuracy: 0.9620 - val_loss: 0.0855 - val_accuracy: 0.9805\n",
      "Epoch 8/70\n",
      "591/591 [==============================] - 237s 400ms/step - loss: 0.1318 - accuracy: 0.9641 - val_loss: 0.0980 - val_accuracy: 0.9750\n",
      "Epoch 9/70\n",
      "591/591 [==============================] - 240s 407ms/step - loss: 0.1224 - accuracy: 0.9670 - val_loss: 0.0773 - val_accuracy: 0.9812\n",
      "Epoch 10/70\n",
      "591/591 [==============================] - 238s 402ms/step - loss: 0.1198 - accuracy: 0.9673 - val_loss: 0.0904 - val_accuracy: 0.9764\n",
      "Epoch 11/70\n",
      "591/591 [==============================] - 238s 402ms/step - loss: 0.1143 - accuracy: 0.9686 - val_loss: 0.0700 - val_accuracy: 0.9795\n",
      "Epoch 12/70\n",
      "591/591 [==============================] - 237s 400ms/step - loss: 0.1061 - accuracy: 0.9709 - val_loss: 0.0780 - val_accuracy: 0.9800\n",
      "Epoch 13/70\n",
      "591/591 [==============================] - 236s 400ms/step - loss: 0.1050 - accuracy: 0.9720 - val_loss: 0.0891 - val_accuracy: 0.9767\n",
      "Epoch 14/70\n",
      "591/591 [==============================] - 236s 400ms/step - loss: 0.1033 - accuracy: 0.9724 - val_loss: 0.0568 - val_accuracy: 0.9855\n",
      "Epoch 15/70\n",
      "591/591 [==============================] - 239s 405ms/step - loss: 0.0973 - accuracy: 0.9749 - val_loss: 0.0619 - val_accuracy: 0.9833\n",
      "Epoch 16/70\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0967 - accuracy: 0.9736 - val_loss: 0.0814 - val_accuracy: 0.9774\n",
      "Epoch 17/70\n",
      "591/591 [==============================] - 240s 406ms/step - loss: 0.0956 - accuracy: 0.9746 - val_loss: 0.0614 - val_accuracy: 0.9836\n",
      "Epoch 18/70\n",
      "591/591 [==============================] - 240s 406ms/step - loss: 0.0918 - accuracy: 0.9753 - val_loss: 0.0623 - val_accuracy: 0.9843\n",
      "Epoch 19/70\n",
      "591/591 [==============================] - 238s 402ms/step - loss: 0.0906 - accuracy: 0.9754 - val_loss: 0.0726 - val_accuracy: 0.9805\n",
      "Epoch 20/70\n",
      "591/591 [==============================] - 239s 405ms/step - loss: 0.0910 - accuracy: 0.9766 - val_loss: 0.0603 - val_accuracy: 0.9857\n",
      "Epoch 21/70\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0853 - accuracy: 0.9780\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "591/591 [==============================] - 236s 399ms/step - loss: 0.0853 - accuracy: 0.9780 - val_loss: 0.0574 - val_accuracy: 0.9850\n",
      "Epoch 22/70\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0652 - accuracy: 0.9820 - val_loss: 0.0433 - val_accuracy: 0.9879\n",
      "Epoch 23/70\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0623 - accuracy: 0.9832 - val_loss: 0.0528 - val_accuracy: 0.9848\n",
      "Epoch 24/70\n",
      "591/591 [==============================] - 236s 400ms/step - loss: 0.0594 - accuracy: 0.9844 - val_loss: 0.0526 - val_accuracy: 0.9874\n",
      "Epoch 25/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0577 - accuracy: 0.9834 - val_loss: 0.0509 - val_accuracy: 0.9857\n",
      "Epoch 26/70\n",
      "591/591 [==============================] - 235s 397ms/step - loss: 0.0531 - accuracy: 0.9849 - val_loss: 0.0498 - val_accuracy: 0.9881\n",
      "Epoch 27/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0581 - accuracy: 0.9838 - val_loss: 0.0592 - val_accuracy: 0.9862\n",
      "Epoch 28/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0542 - accuracy: 0.9850 - val_loss: 0.0592 - val_accuracy: 0.9855\n",
      "Epoch 29/70\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9849\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 0.0593 - val_accuracy: 0.9883\n",
      "Epoch 30/70\n",
      "591/591 [==============================] - 239s 405ms/step - loss: 0.0450 - accuracy: 0.9869 - val_loss: 0.0509 - val_accuracy: 0.9879\n",
      "Epoch 31/70\n",
      "591/591 [==============================] - 235s 397ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.0438 - val_accuracy: 0.9886\n",
      "Epoch 32/70\n",
      "591/591 [==============================] - 239s 404ms/step - loss: 0.0396 - accuracy: 0.9878 - val_loss: 0.0457 - val_accuracy: 0.9890\n",
      "Epoch 33/70\n",
      "591/591 [==============================] - 241s 408ms/step - loss: 0.0407 - accuracy: 0.9878 - val_loss: 0.0480 - val_accuracy: 0.9890\n",
      "Epoch 34/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0410 - accuracy: 0.9881 - val_loss: 0.0461 - val_accuracy: 0.9905\n",
      "Epoch 35/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 0.0555 - val_accuracy: 0.9888\n",
      "Epoch 36/70\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9888\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0398 - accuracy: 0.9888 - val_loss: 0.0438 - val_accuracy: 0.9890\n",
      "Epoch 37/70\n",
      "591/591 [==============================] - 241s 407ms/step - loss: 0.0339 - accuracy: 0.9897 - val_loss: 0.0494 - val_accuracy: 0.9912\n",
      "Epoch 38/70\n",
      "591/591 [==============================] - 239s 404ms/step - loss: 0.0296 - accuracy: 0.9907 - val_loss: 0.0630 - val_accuracy: 0.9900\n",
      "Epoch 39/70\n",
      "591/591 [==============================] - 240s 407ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.0623 - val_accuracy: 0.9888\n",
      "Epoch 40/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0297 - accuracy: 0.9911 - val_loss: 0.0562 - val_accuracy: 0.9898\n",
      "Epoch 41/70\n",
      "591/591 [==============================] - 240s 407ms/step - loss: 0.0317 - accuracy: 0.9909 - val_loss: 0.0483 - val_accuracy: 0.9900\n",
      "Epoch 42/70\n",
      "591/591 [==============================] - 238s 402ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.0441 - val_accuracy: 0.9910\n",
      "Epoch 43/70\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9906\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "591/591 [==============================] - 238s 402ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.0462 - val_accuracy: 0.9921\n",
      "Epoch 44/70\n",
      "591/591 [==============================] - 238s 402ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.0511 - val_accuracy: 0.9893\n",
      "Epoch 45/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.0480 - val_accuracy: 0.9895\n",
      "Epoch 46/70\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 0.0467 - val_accuracy: 0.9902\n",
      "Epoch 47/70\n",
      "591/591 [==============================] - 239s 404ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0472 - val_accuracy: 0.9893\n",
      "Epoch 48/70\n",
      "591/591 [==============================] - 237s 402ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.0456 - val_accuracy: 0.9907\n",
      "Epoch 49/70\n",
      "591/591 [==============================] - 238s 404ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.0467 - val_accuracy: 0.9910\n",
      "Epoch 50/70\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9910\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0306 - accuracy: 0.9910 - val_loss: 0.0478 - val_accuracy: 0.9910\n",
      "Epoch 51/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 236s 400ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.0447 - val_accuracy: 0.9902\n",
      "Epoch 52/70\n",
      "591/591 [==============================] - 236s 399ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.0460 - val_accuracy: 0.9898\n",
      "Epoch 53/70\n",
      "591/591 [==============================] - 239s 404ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0443 - val_accuracy: 0.9914\n",
      "Epoch 54/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0452 - val_accuracy: 0.9914\n",
      "Epoch 55/70\n",
      "591/591 [==============================] - 237s 402ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0474 - val_accuracy: 0.9910\n",
      "Epoch 56/70\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0456 - val_accuracy: 0.9912\n",
      "Epoch 57/70\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9916\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0462 - val_accuracy: 0.9912\n",
      "Epoch 58/70\n",
      "591/591 [==============================] - 236s 400ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0476 - val_accuracy: 0.9905\n",
      "Epoch 59/70\n",
      "591/591 [==============================] - 240s 406ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0489 - val_accuracy: 0.9898\n",
      "Epoch 60/70\n",
      "591/591 [==============================] - 239s 405ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0482 - val_accuracy: 0.9907\n",
      "Epoch 61/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.0476 - val_accuracy: 0.9902\n",
      "Epoch 62/70\n",
      "591/591 [==============================] - 239s 404ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.0464 - val_accuracy: 0.9905\n",
      "Epoch 63/70\n",
      "591/591 [==============================] - 239s 405ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0496 - val_accuracy: 0.9902\n",
      "Epoch 64/70\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9931\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "591/591 [==============================] - 240s 405ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0516 - val_accuracy: 0.9898\n",
      "Epoch 65/70\n",
      "591/591 [==============================] - 237s 401ms/step - loss: 0.0247 - accuracy: 0.9930 - val_loss: 0.0500 - val_accuracy: 0.9898\n",
      "Epoch 66/70\n",
      "591/591 [==============================] - 240s 405ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0506 - val_accuracy: 0.9900\n",
      "Epoch 67/70\n",
      "591/591 [==============================] - 233s 394ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.0505 - val_accuracy: 0.9905\n",
      "Epoch 68/70\n",
      "591/591 [==============================] - 240s 407ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.0508 - val_accuracy: 0.9905\n",
      "Epoch 69/70\n",
      "591/591 [==============================] - 238s 403ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0509 - val_accuracy: 0.9907\n",
      "Epoch 70/70\n",
      "591/591 [==============================] - 240s 407ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0507 - val_accuracy: 0.9905\n",
      "4200/4200 [==============================] - 1s 233us/sample - loss: 0.0510 - accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "val,his,ypred=run(TestConvModel,Xn_train,Ye_train, Xn_val, Ye_val,Xn_test,64,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ConvModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          1664      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 3, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 256)         819456    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 1, 1, 512)         524800    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 5,571,850\n",
      "Trainable params: 5,571,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = TestConvModel(Xn_train[-1].shape)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(his.history['accuracy'])\n",
    "plt.plot(his.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(his.history['loss'])\n",
    "plt.plot(his.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.814500582928663"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(his.history['loss'][30]-his.history['val_loss'][30])/his.history['loss'][30] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9875212"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his.history['accuracy'][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest=np.argmax(ypred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## printing random hand-written digits\n",
    "indx = np.arange(len(Xn_test)) #np.random.randint(0,len(Xn_test)-1,size=10)\n",
    "fig = plt.figure()\n",
    "for ix in range(10):\n",
    "    ax = fig.add_subplot(5, 5, 1 + ix)\n",
    "    ax.imshow(Xn_test[indx[ix],:,:,0])\n",
    "    ax.set_title('y='+str(ytest[indx[ix]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = np.arange(len(Xn_test))\n",
    "submission = pd.DataFrame({\n",
    "        \"ImageId\": image_id,\n",
    "        \"Label\": ytest\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lenet5Model(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the ConvModel.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    # Define the input placeholder as a tensor with shape input_shape. \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # \n",
    "    X = ZeroPadding2D((2, 2))(X_input)\n",
    "    print(np.shape(X))\n",
    "    X = Conv2D(6,5,1,kernel_initializer='he_normal')(X)\n",
    "    print(np.shape(X))\n",
    "    X = AveragePooling2D(pool_size=(2,2),strides=2)(X)\n",
    "    print(np.shape(X))\n",
    "    X = Conv2D(16,5,1,kernel_initializer='he_normal')(X)\n",
    "    print(np.shape(X))\n",
    "    X = AveragePooling2D(pool_size=(2,2),strides=2)(X)\n",
    "    print(np.shape(X))\n",
    "    X = Flatten()(X)\n",
    "    print(np.shape(X))\n",
    "    X = Dense(120, activation='relu', kernel_initializer='he_normal')(X)\n",
    "    print(np.shape(X))\n",
    "    X = Dense(84, activation='relu', kernel_initializer='he_normal')(X)\n",
    "    print(np.shape(X))\n",
    "    predictions = Dense(10, activation=\"softmax\")(X)\n",
    "    print(np.shape(predictions))\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = predictions, name='Lenet5Model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32, 1)\n",
      "(None, 28, 28, 6)\n",
      "(None, 14, 14, 6)\n",
      "(None, 10, 10, 16)\n",
      "(None, 5, 5, 16)\n",
      "(None, 400)\n",
      "(None, 120)\n",
      "(None, 84)\n",
      "(None, 84)\n",
      "Epoch 1/300\n",
      "591/591 [==============================] - 21s 36ms/step - loss: 0.4312 - accuracy: 0.8646 - val_loss: 0.1839 - val_accuracy: 0.9469\n",
      "Epoch 2/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.2280 - accuracy: 0.9297 - val_loss: 0.1360 - val_accuracy: 0.9619\n",
      "Epoch 3/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.1825 - accuracy: 0.9426 - val_loss: 0.1100 - val_accuracy: 0.9662\n",
      "Epoch 4/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.1560 - accuracy: 0.9510 - val_loss: 0.1059 - val_accuracy: 0.9724\n",
      "Epoch 5/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.1399 - accuracy: 0.9565 - val_loss: 0.1193 - val_accuracy: 0.9669\n",
      "Epoch 6/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.1329 - accuracy: 0.9570 - val_loss: 0.0999 - val_accuracy: 0.9702\n",
      "Epoch 7/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.1273 - accuracy: 0.9605 - val_loss: 0.0872 - val_accuracy: 0.9707\n",
      "Epoch 8/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.1166 - accuracy: 0.9633 - val_loss: 0.0796 - val_accuracy: 0.9748\n",
      "Epoch 9/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.1101 - accuracy: 0.9648 - val_loss: 0.0945 - val_accuracy: 0.9719\n",
      "Epoch 10/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.1079 - accuracy: 0.9649 - val_loss: 0.0847 - val_accuracy: 0.9748\n",
      "Epoch 11/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.1033 - accuracy: 0.9671 - val_loss: 0.0709 - val_accuracy: 0.9781\n",
      "Epoch 12/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.1009 - accuracy: 0.9681 - val_loss: 0.0729 - val_accuracy: 0.9790\n",
      "Epoch 13/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0937 - accuracy: 0.9700 - val_loss: 0.0680 - val_accuracy: 0.9779\n",
      "Epoch 14/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0920 - accuracy: 0.9702 - val_loss: 0.0680 - val_accuracy: 0.9790\n",
      "Epoch 15/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0884 - accuracy: 0.9719 - val_loss: 0.0642 - val_accuracy: 0.9824\n",
      "Epoch 16/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0872 - accuracy: 0.9720 - val_loss: 0.0689 - val_accuracy: 0.9824\n",
      "Epoch 17/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0838 - accuracy: 0.9728 - val_loss: 0.0674 - val_accuracy: 0.9783\n",
      "Epoch 18/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0848 - accuracy: 0.9728 - val_loss: 0.0724 - val_accuracy: 0.9790\n",
      "Epoch 19/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0793 - accuracy: 0.9749 - val_loss: 0.0725 - val_accuracy: 0.9793\n",
      "Epoch 20/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0778 - accuracy: 0.9747 - val_loss: 0.0685 - val_accuracy: 0.9826\n",
      "Epoch 21/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0800 - accuracy: 0.9751 - val_loss: 0.0691 - val_accuracy: 0.9817\n",
      "Epoch 22/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9761\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0729 - accuracy: 0.9761 - val_loss: 0.0643 - val_accuracy: 0.9805\n",
      "Epoch 23/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0625 - accuracy: 0.9795 - val_loss: 0.0615 - val_accuracy: 0.9817\n",
      "Epoch 24/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0609 - accuracy: 0.9807 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
      "Epoch 25/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0595 - accuracy: 0.9803 - val_loss: 0.0579 - val_accuracy: 0.9843\n",
      "Epoch 26/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0568 - accuracy: 0.9814 - val_loss: 0.0627 - val_accuracy: 0.9817\n",
      "Epoch 27/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 0.0556 - val_accuracy: 0.9838\n",
      "Epoch 28/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0550 - accuracy: 0.9821 - val_loss: 0.0660 - val_accuracy: 0.9814\n",
      "Epoch 29/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.0551 - val_accuracy: 0.9826\n",
      "Epoch 30/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0537 - accuracy: 0.9827 - val_loss: 0.0599 - val_accuracy: 0.9812\n",
      "Epoch 31/300\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 0.9825\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0549 - accuracy: 0.9826 - val_loss: 0.0593 - val_accuracy: 0.9833\n",
      "Epoch 32/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0486 - accuracy: 0.9837 - val_loss: 0.0584 - val_accuracy: 0.9829\n",
      "Epoch 33/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 0.0561 - val_accuracy: 0.9840\n",
      "Epoch 34/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0449 - accuracy: 0.9850 - val_loss: 0.0603 - val_accuracy: 0.9826\n",
      "Epoch 35/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0450 - accuracy: 0.9855 - val_loss: 0.0547 - val_accuracy: 0.9833\n",
      "Epoch 36/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 0.0594 - val_accuracy: 0.9824\n",
      "Epoch 37/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0447 - accuracy: 0.9854 - val_loss: 0.0596 - val_accuracy: 0.9838\n",
      "Epoch 38/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9866\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 0.0577 - val_accuracy: 0.9845\n",
      "Epoch 39/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0427 - accuracy: 0.9859 - val_loss: 0.0581 - val_accuracy: 0.9845\n",
      "Epoch 40/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0563 - val_accuracy: 0.9845\n",
      "Epoch 41/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0388 - accuracy: 0.9869 - val_loss: 0.0551 - val_accuracy: 0.9850\n",
      "Epoch 42/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0376 - accuracy: 0.9877 - val_loss: 0.0570 - val_accuracy: 0.9838\n",
      "Epoch 43/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.0572 - val_accuracy: 0.9852\n",
      "Epoch 44/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0388 - accuracy: 0.9873 - val_loss: 0.0561 - val_accuracy: 0.9848\n",
      "Epoch 45/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.0542 - val_accuracy: 0.9860\n",
      "Epoch 46/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.0565 - val_accuracy: 0.9850\n",
      "Epoch 47/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0373 - accuracy: 0.9876 - val_loss: 0.0572 - val_accuracy: 0.9843\n",
      "Epoch 48/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.0582 - val_accuracy: 0.9843\n",
      "Epoch 49/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0356 - accuracy: 0.9888 - val_loss: 0.0582 - val_accuracy: 0.9857\n",
      "Epoch 50/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0351 - accuracy: 0.9879 - val_loss: 0.0605 - val_accuracy: 0.9848\n",
      "Epoch 51/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0392 - accuracy: 0.9869 - val_loss: 0.0573 - val_accuracy: 0.9848\n",
      "Epoch 52/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9872\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0380 - accuracy: 0.9871 - val_loss: 0.0583 - val_accuracy: 0.9840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 0.0581 - val_accuracy: 0.9843\n",
      "Epoch 54/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 0.0556 - val_accuracy: 0.9845\n",
      "Epoch 55/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0362 - accuracy: 0.9880 - val_loss: 0.0555 - val_accuracy: 0.9857\n",
      "Epoch 56/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.0578 - val_accuracy: 0.9855\n",
      "Epoch 57/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.0560 - val_accuracy: 0.9848\n",
      "Epoch 58/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.0568 - val_accuracy: 0.9843\n",
      "Epoch 59/300\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9884\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.0573 - val_accuracy: 0.9848\n",
      "Epoch 60/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.0586 - val_accuracy: 0.9840\n",
      "Epoch 61/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0321 - accuracy: 0.9891 - val_loss: 0.0590 - val_accuracy: 0.9840\n",
      "Epoch 62/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 0.0574 - val_accuracy: 0.9845\n",
      "Epoch 63/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0335 - accuracy: 0.9893 - val_loss: 0.0563 - val_accuracy: 0.9852\n",
      "Epoch 64/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0345 - accuracy: 0.9883 - val_loss: 0.0576 - val_accuracy: 0.9843\n",
      "Epoch 65/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 0.0571 - val_accuracy: 0.9852\n",
      "Epoch 66/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9892\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 0.0562 - val_accuracy: 0.9843\n",
      "Epoch 67/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0347 - accuracy: 0.9885 - val_loss: 0.0572 - val_accuracy: 0.9845\n",
      "Epoch 68/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0322 - accuracy: 0.9891 - val_loss: 0.0586 - val_accuracy: 0.9843\n",
      "Epoch 69/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.0587 - val_accuracy: 0.9845\n",
      "Epoch 70/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.0580 - val_accuracy: 0.9850\n",
      "Epoch 71/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0573 - val_accuracy: 0.9843\n",
      "Epoch 72/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.0575 - val_accuracy: 0.9850\n",
      "Epoch 73/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9892\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.0573 - val_accuracy: 0.9850\n",
      "Epoch 74/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.0583 - val_accuracy: 0.9848\n",
      "Epoch 75/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.0579 - val_accuracy: 0.9843\n",
      "Epoch 76/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0577 - val_accuracy: 0.9848\n",
      "Epoch 77/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0331 - accuracy: 0.9892 - val_loss: 0.0578 - val_accuracy: 0.9848\n",
      "Epoch 78/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0578 - val_accuracy: 0.9843\n",
      "Epoch 79/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 0.0581 - val_accuracy: 0.9845\n",
      "Epoch 80/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9897\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.0577 - val_accuracy: 0.9848\n",
      "Epoch 81/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.0579 - val_accuracy: 0.9852\n",
      "Epoch 82/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.0580 - val_accuracy: 0.9848\n",
      "Epoch 83/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0321 - accuracy: 0.9891 - val_loss: 0.0581 - val_accuracy: 0.9848\n",
      "Epoch 84/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 85/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 86/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0312 - accuracy: 0.9889 - val_loss: 0.0579 - val_accuracy: 0.9850\n",
      "Epoch 87/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9902\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0579 - val_accuracy: 0.9850\n",
      "Epoch 88/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 89/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0310 - accuracy: 0.9896 - val_loss: 0.0579 - val_accuracy: 0.9850\n",
      "Epoch 90/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 0.0579 - val_accuracy: 0.9850\n",
      "Epoch 91/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0579 - val_accuracy: 0.9850\n",
      "Epoch 92/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0324 - accuracy: 0.9889 - val_loss: 0.0579 - val_accuracy: 0.9850\n",
      "Epoch 93/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0319 - accuracy: 0.9892 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 94/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9894\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0319 - accuracy: 0.9894 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 95/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.0577 - val_accuracy: 0.9850\n",
      "Epoch 96/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.0577 - val_accuracy: 0.9850\n",
      "Epoch 97/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0324 - accuracy: 0.9888 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 98/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 99/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0313 - accuracy: 0.9891 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 100/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 101/300\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9895\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0316 - accuracy: 0.9895 - val_loss: 0.0578 - val_accuracy: 0.9850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 103/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 104/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0318 - accuracy: 0.9893 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 105/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 106/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 107/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0577 - val_accuracy: 0.9850\n",
      "Epoch 108/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9889\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 109/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 110/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 111/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0319 - accuracy: 0.9901 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 112/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 113/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 114/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0313 - accuracy: 0.9894 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 115/300\n",
      "590/591 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9885\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0340 - accuracy: 0.9886 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 116/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 117/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 118/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 119/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0320 - accuracy: 0.9898 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 120/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0323 - accuracy: 0.9890 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 121/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 122/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9895\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 123/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0295 - accuracy: 0.9901 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 124/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0308 - accuracy: 0.9898 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 125/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 126/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 127/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0578 - val_accuracy: 0.9850\n",
      "Epoch 128/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.0578 - val_accuracy: 0.9848\n",
      "Epoch 129/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9895\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 130/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 131/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 132/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0302 - accuracy: 0.9901 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 133/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0326 - accuracy: 0.9894 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 134/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 135/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 136/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9889\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 137/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 138/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 139/300\n",
      "591/591 [==============================] - 21s 36ms/step - loss: 0.0325 - accuracy: 0.9889 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 140/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 141/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 142/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0319 - accuracy: 0.9890 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 143/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9894\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0312 - accuracy: 0.9894 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 144/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 145/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0299 - accuracy: 0.9898 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 146/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0337 - accuracy: 0.9892 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 147/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0332 - accuracy: 0.9886 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 148/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0302 - accuracy: 0.9896 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 149/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 150/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9898\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 0.0579 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0315 - accuracy: 0.9889 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 152/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0314 - accuracy: 0.9898 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 153/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 154/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 155/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 156/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 157/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9894\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0311 - accuracy: 0.9894 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 158/300\n",
      "591/591 [==============================] - 20s 35ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 159/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 160/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 161/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 162/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 163/300\n",
      "591/591 [==============================] - 21s 35ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 164/300\n",
      "589/591 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9894\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 165/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 166/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 167/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0313 - accuracy: 0.9897 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 168/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0310 - accuracy: 0.9898 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 169/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 170/300\n",
      "591/591 [==============================] - 20s 34ms/step - loss: 0.0316 - accuracy: 0.9895 - val_loss: 0.0579 - val_accuracy: 0.9848\n",
      "Epoch 171/300\n",
      "403/591 [===================>..........] - ETA: 6s - loss: 0.0319 - accuracy: 0.9898"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8b22e6a01280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlhis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlypred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLenet5Model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXn_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYe_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXn_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYe_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXn_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-c9c99af8ef03>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(Model, xdata, ydata, xval, yval, xtest, bs, nb)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# reduce the learning rate by factor of 0.5 if the validation loss does not get lower in 7 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreduce_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m##history = model.fit(x = xdata, y = ydata, epochs = 40, batch_size = bs,validation_data= (xval,yval),callbacks=[es])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmval\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/machine_learning/codes/mlp/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/Documents/work/machine_learning/codes/mlp/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/machine_learning/codes/mlp/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/machine_learning/codes/mlp/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/Documents/work/machine_learning/codes/mlp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/machine_learning/codes/mlp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/machine_learning/codes/mlp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/machine_learning/codes/mlp/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lval,lhis,lypred=run(Lenet5Model,Xn_train,Ye_train, Xn_val, Ye_val,Xn_test,64,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (mlp)",
   "language": "python",
   "name": "mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
